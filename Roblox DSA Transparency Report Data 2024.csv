Roblox EU Digital Safety Act (DSA) Transparency Report,,,,,,,,,,,,,,,,,,,,,,,,,
1. Cover Sheet,,,,,,,,,,,,,,,,,,,,,,,,,
Context,"Roblox provides the information below in response to the DSA. The following data covers the time period from Feb. 17, 2024 through Dec. 31, 2024 (the reporting period). 

To provide greater context on the charts below, during the reporting period, Roblox users generated and uploaded approximately 1.1 trillion (1,109,155,652,855) total pieces of content to our platform, of which a significant amount is text chat, as well as other content types including audio, voice, and images. Every piece of content generated and uploaded is reviewed by our content moderation tools. Thus, this number represents the total pieces of content that potentially could have been flagged via our detection and reporting systems. 

Just 0.0103% of all content uploaded (114,246,370 total pieces of content) was detected as violating our policies. This content is immediately removed from the platform and depending on the severity of the violation, proportionate action is taken on the account that uploaded the content.",,,,,,,,,,,,,,,,,,,,,,,,
Report publication date: ,"February 14, 2025",,,,,,,,,,,,,,,,,,,,,,,,
Reporting period: ,"Feburary 17, 2024 to December 31, 2024",,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
2. Orders from authorities (Art. 15(1)(a) DSA),,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,2.1 Numbers of orders received from Member States’ authorities under Art. 9 and 10,0,,,,,,,,,,,,,,,,,,,,,,,
,2.2 Categorized by the type of illegal content concerned,n/a,,,,,,,,,,,,,,,,,,,,,,,
,2.3 Categorized by the Member State issuing the order,n/a,,,,,,,,,,,,,,,,,,,,,,,
,2.4 Median time needed to inform the authority issuing the order of the receipt,n/a,,,,,,,,,,,,,,,,,,,,,,,
,2.5 Median time to give effect to order,n/a,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
3. User notices (Art. 15(1)(b) DSA),,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,3.1 Notices submitted in accordance with Art. 16,"371,934",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,3.2 Categorized by the type of alleged illegal content concerned,,,,,,,,,,,,,,,,,,,,,,,,
,Child Sexual Exploitation,105360,,,,,,,,,,,,,,,,,,,,,,,
,Hate Speech,26998,,,,,,,,,,,,,,,,,,,,,,,
,Illegal Goods and Activities,63346,,,,,,,,,,,,,,,,,,,,,,,
,IP Infringement,39,,,,,,,,,,,,,,,,,,,,,,,
,Other,123679,,,,,,,,,,,,,,,,,,,,,,,
,Scams,9274,,,,,,,,,,,,,,,,,,,,,,,
,Terrorism & Violent Extremism,36319,,,,,,,,,,,,,,,,,,,,,,,
,Threats of Violence,6919,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,3.3 Number of notices submitted by trusted flaggers,8,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,3.4 Number of notices actioned pursuant to the notices by differentiating between illegal content and T&C violations,,,,,,,,,,,,,,,,,,,,,,,,
,Illegal content,1,,,,,,,,,,,,,,,,,,,,,,,
,Community Standards (T&C) violations,"371,933",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,3.5 Number of notices processed by using automated means,0,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,3.6 Median time needed for taking the action,10 minutes,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
4. Content moderation (Art. 15(1)(c) DSA),,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,4.1 Information about the content moderation engaged in at the providers’ own initiative,"Automated and human content moderation: a combination of automated and human content moderation systems play a crucial role in enforcing our policies by proactively identifying and removing violating content. Content uploaded on the platform such as images undergo a comprehensive review process before it’s published, while content such as voice-chat communications are assessed for policy violations in real-time.
",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,4.2 Including the use of automated tools,"When experiences are published or updated on the Roblox Platform, they are evaluated by a suite of AI driven tools that identify problematic language, potential bypasses to our safety systems, and content that falls outside our policies. A human review team is continuously operating to evaluate flagged experiences. The Roblox Platform includes a suite of anti-intruder technology leveraging machine learning, throttles, and circuit breakers designed to block automated bot attacks and mitigate the impact of humans who attempt to spam users and disrupt the service. We also leverage targeted penetration testing, a bug bounty program, code reviews, secure by design principles, targeted security testing, and vulnerability scanning to promote the security of the Platform.",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,4.3 Measures taken to provide training and assistance to moderators,"Moderators are trained on the implementation of our policies. Training includes coaching on the application and interpretation of Roblox’s policies, practice implementing those policies on example sets of potential violations, and finally, assessments. Moderators are regularly evaluated for accuracy and are providedl remedial training as necessary.

Additionally, Roblox supports its moderators with regular well-being check-ins, 24/7 on-demand support from a licensed clinician, peer support groups, wellness workshops, and individual or group counseling sessions. Roblox evaluates these wellness offerings semi-annually for effectiveness and to identify areas for improvement.",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,4.4 Categorized by the type of illegal content or violation of the terms and conditions of the service provider,,,,,,,,,,,,,,,,,,,,,,,,
,"Threats, Bullying, and Harassment","35,186,136",,,,,,,,,,,,,,,,,,,,,,,
,Romantic and Sexual Content,"22,271,499",,,,,,,,,,,,,,,,,,,,,,,
,Spam,"20,922,758",,,,,,,,,,,,,,,,,,,,,,,
,"Discrimination, Slurs, and Hate Speech","14,819,623",,,,,,,,,,,,,,,,,,,,,,,
,Profanity,"8,131,698",,,,,,,,,,,,,,,,,,,,,,,
,Sharing Personal Information,"3,686,152",,,,,,,,,,,,,,,,,,,,,,,
,Cheating and Scams,"3,316,541",,,,,,,,,,,,,,,,,,,,,,,
,Misusing Roblox Systems,"2,122,666",,,,,,,,,,,,,,,,,,,,,,,
,Other,"1,788,950",,,,,,,,,,,,,,,,,,,,,,,
,Illegal and Regulated Goods and Activities,"690,634",,,,,,,,,,,,,,,,,,,,,,,
,Directing Users Off-Platform,"493,339",,,,,,,,,,,,,,,,,,,,,,,
,Violent Content and Gore,"235,652",,,,,,,,,,,,,,,,,,,,,,,
,Real-World Sensitive Events,"185,655",,,,,,,,,,,,,,,,,,,,,,,
,Political Figures and Entities,"112,349",,,,,,,,,,,,,,,,,,,,,,,
,Terrorism and Violent Extremism,"99,057",,,,,,,,,,,,,,,,,,,,,,,
,Intellectual Property Violations,"82,508",,,,,,,,,,,,,,,,,,,,,,,
,"Suicide, Self Injury, and Harmful Behavior","46,264",,,,,,,,,,,,,,,,,,,,,,,
,Child Exploitation,"42,848",,,,,,,,,,,,,,,,,,,,,,,
,Roblox Economy,"9,507",,,,,,,,,,,,,,,,,,,,,,,
,Advertising,1705,,,,,,,,,,,,,,,,,,,,,,,
,Off Platform Behaviour,829,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,4.5 Categorized by the detection method,,,,,,,,,,,,,,,,,,,,,,,,
,Automation,"19,897,782",,,,,,,,,,,,,,,,,,,,,,,
,Manual,"94,348,588",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,4.6 Categorized by the type of restriction,,,,,,,,,,,,,,,,,,,,,,,,
,Content removal,"20,253,498",,,,,,,,,,,,,,,,,,,,,,,
,Account suspension,"58,522,615",,,,,,,,,,,,,,,,,,,,,,,
,Account termination,"164,883",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
5. Complaints received against decisions (Art. 15(1)(d) DSA)*,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,5.1 Number of complaints received through the internal complaint-handling systems,"636,067",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,5.2 Basis for those complaints in accordance with Art. 20 DSA,,,,,,,,,,,,,,,,,,,,,,,,
,Actions taken against content or an account,"633,939",,,,,,,,,,,,,,,,,,,,,,,
,Decisions rejecting a request to take action against content or an account ,"2,128",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,5.3 Decisions taken in respect of those complaints,,,,,,,,,,,,,,,,,,,,,,,,
,Initial decision upheld,"550,502",,,,,,,,,,,,,,,,,,,,,,,
,Initial decision overturned,"85,565",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,5.4 Median time needed for taking those decisions,3 hr 7 minutes,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,*EU data only,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
6. Automated content moderation (Art. 15(1)(e) DSA,,,,,,,,,,,,,,,,,,,,,,,,,
,6.1 Have automated means been used for content moderation?,Yes,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,6.2 Qualitative description of the means,"Our ML models detect policy-violating text, images, speech, and 3D models comprehensively across Roblox; this content is reviewed by both our automated and/or manual systems. These models are trained on Roblox-specific language and abbreviations, and are able to consider the context of potential violations that would likely be missed by other ML models.

For visual assets, we use computer vision (CV) to detect violating avatars and avatar accessories. As an example, one CV technique Roblox employs involves taking photographs of avatars and items from multiple angles to detect and determine if it may be violating a policy; our ML models are trained to detect if images produced by CV are violating any of our policies.

For voice chat, we use Automatic Speech Recognition (ASR) to transcribe voice into text, then use an in-house AI model to classify and detect policy-violating language. This is done in real-time, allowing us to take action such as temporarily suspending or banning users violating policies in voice chats on Roblox.",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,6.3 Specification of the precise purposes,"We use our automated and manual content moderation systems to review whether content on Roblox complies with our policies. These policies are enforced globally. We take the safety of our users seriously so that users' experience on Roblox stays safe, welcoming, and fun. ",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,6.4 Indicators of the accuracy and the possible rate of error,"While our goal is to provide industry-leading moderation to enforce our policies, no such system is perfect, and Roblox cannot ensure that users will not encounter content that violates policies. We’re constantly improving our moderation capabilities to correctly detect and take action on violating content. We measure our automation’s accuracy with a variety of metrics. This report contains our data on recall, the percent of violating content our automation tools are able to identify across a set of content.

Below are definitions for each type of content and our models' recall for each:

Places: User-generated game levels; an ""experience"" on Roblox may contain one or multiple places.
Images: Image files to users upload to Roblox, such as screenshots or textures.
Audio: Audio files users upload to Roblox, such as voicelines or music.

Place with recall of 89%
Image with recall of 73.5%
Audio with recall of 97%",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,6.5 Any safeguards applied,"Content not flagged for removal by automated systems is subject to human review when it’s (1) reported by users, (2) reviewed for QA purposes, or (3) when our automated systems aren’t sure what action should be taken. Content that meets any of these three conditions is sent to a human moderator to make the final decision. Additionally, we have automated systems in place to help prevent the re-upload of content that we’ve previously removed or rejected so that content we’ve taken down isn’t reintroduced to the platform.

We identify areas to improve our automation by randomly sampling the decisions made by automation across different content types and then having human moderators review and verify the accuracy of the automated decision. The assessments by the human moderators are fed back into the machine learning model, enabling it to more accurately identify and distinguish violating/non-violating content in the future.",,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
7. Out-of-court dispute settlement (Art. 24(1)(a) DSA),,,,,,,,,,,,,,,,,,,,,,,,,
,7.1 Number of disputes submitted to the out-of-court dispute settlement bodies,34,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,7.2 Outcomes of the dispute settlement,,,,,,,,,,,,,,,,,,,,,,,,
,Final decision of the provider upheld,3,,,,,,,,,,,,,,,,,,,,,,,
,Final decision of the provider overturned,4,,,,,,,,,,,,,,,,,,,,,,,
,Other,0,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,7.3 Median time needed for completing the dispute settlement procedures,64 days,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,7.4 Share of disputes where the provider of the online platform implemented the decisions of the body,43%,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
8. Suspensions for misuse (Art. 24(1)(b) DSA,,,,,,,,,,,,,,,,,,,,,,,,,
,8. 1Number of suspensions enacted for the provision of manifestly illegal content,0,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,8.2 Number of suspensions for manifestly unfounded notices (under Art. 16 DSA),0,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,8.3 Number of suspensions for manifestly unfounded complaints (under Art. 20 DSA),0,,,,,,,,,,,,,,,,,,,,,,,